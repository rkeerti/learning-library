{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cdea7c6",
   "metadata": {},
   "source": [
    "# <b>Image classification batch feature demo</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6863dac6",
   "metadata": {},
   "source": [
    "The AIServiceVisionClient offers the image classification feature in batch mode. This notebook aims to provide overall clarity about the feature to the user in terms of requirements, usage and the output of the batch i.e. asynchronous API.<br>\n",
    "<ul>\n",
    "    <li>The output response files are stored at the object storage specified in <code>data/output_object_image_batch.json</code>. </li>\n",
    "<li>The detected classes for a random input image are displayed in the last section of the notebook.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca79289",
   "metadata": {},
   "source": [
    "### Steps to run the notebook:\n",
    "<details>\n",
    "    <summary>Notebook session setup</summary>\n",
    "    <ol>\n",
    "        <li><font size=\"2\">Installing the OCI Vision SDK</font></li>\n",
    "        <li><font size=\"2\">Installing other dependencies</font></li>\n",
    "        <li><font size=\"2\">Setup sample input images</font></li>\n",
    "        <li><font size=\"2\">Setup helper .py files</font></li>\n",
    "    </ol>\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "    <summary>Importing the required modules</summary>\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "    <summary>Setting the input variables</summary>\n",
    "     <font size=\"2\">The user can change the input variables, if necessary. They have been assigned default values.</font>\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "    <summary>Running the main pipeline</summary>\n",
    "    <font size=\"2\">Run all cells to get the output in the <code>output</code> directory. </font><br>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2d06f3",
   "metadata": {},
   "source": [
    "### Notebook session setup\n",
    "<details>\n",
    "    <summary>Instructions</summary>\n",
    "    <ul>\n",
    "        <li><font size=\"2\">The user needs to setup only once.</font></li>\n",
    "        <li><font size=\"2\">Uncomment the commented cells and run once to setup.</font></li>\n",
    "        <li><font size=\"2\">Comment back the same cells to avoid running again.</font></li>\n",
    "    </ul>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f734fde",
   "metadata": {},
   "source": [
    "#### Installing the OCI Vision SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d6d88f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget \"https://objectstorage.us-ashburn-1.oraclecloud.com/n/axhheqi2ofpb/b/vision-demo-notebooks/o/vision_service_python_client-0.3.45-py2.py3-none-any.whl\"\n",
    "# !pip install vision_service_python_client-0.3.45-py2.py3-none-any.whl\n",
    "# !rm vision_service_python_client-0.3.45-py2.py3-none-any.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89172617",
   "metadata": {},
   "source": [
    "#### Installing other dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4a1d1d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install matplotlib==3.3.4\n",
    "# !pip install pandas==1.1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4511ae9f",
   "metadata": {},
   "source": [
    "#### Setup sample input images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8836ca55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget \"https://objectstorage.us-ashburn-1.oraclecloud.com/n/axhheqi2ofpb/b/vision-demo-notebooks/o/input_objects_image_batch.json\"\n",
    "# !wget \"https://objectstorage.us-ashburn-1.oraclecloud.com/n/axhheqi2ofpb/b/vision-demo-notebooks/o/output_object_image_batch.json\"\n",
    "# !mkdir data\n",
    "# !mv input_objects_image_batch.json data\n",
    "# !mv output_object_image_batch.json data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e88c95",
   "metadata": {},
   "source": [
    "#### Setup helper .py files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "551ca950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget \"https://objectstorage.us-ashburn-1.oraclecloud.com/n/axhheqi2ofpb/b/vision-demo-notebooks/o/analyze_image_batch_utils.py\"\n",
    "# !mkdir helper\n",
    "# !mv analyze_image_batch_utils.py helper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd734e9",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8b785f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import io\n",
    "from random import randint\n",
    "import oci\n",
    "from PIL import Image\n",
    "\n",
    "from vision_service_python_client.models import output_location\n",
    "from vision_service_python_client.ai_service_vision_client import AIServiceVisionClient\n",
    "from vision_service_python_client.models.create_image_job_details import CreateImageJobDetails\n",
    "from vision_service_python_client.models.image_classification_feature import ImageClassificationFeature\n",
    "from helper.analyze_image_batch_utils import load_input_object_locations, load_output_object_location, display_classes, clean_output\n",
    "from IPython.display import JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff212f2e",
   "metadata": {},
   "source": [
    "### Set input variables\n",
    "<details>\n",
    "    <summary><font size=\"3\">input_location_path</font></summary>\n",
    "    <font size=\"2\">The file <code>data/input_objects_image_batch.json</code> specifies where the input images are to be taken from. Sample file has been provided. The user needs to provide the following in this file:\n",
    "        <ul>\n",
    "            <li><code>compartment_id</code> : Compartment ID</li>\n",
    "            <li><code>input_objects</code>: List with the object locations in the following format-</li>\n",
    "            <ul>\n",
    "                <li><code>namespace</code> : Namespace name</li>\n",
    "                <li><code>bucket</code> : Bucket name</li>\n",
    "                <li><code>objects</code> : List of object names</li>\n",
    "            </ul>\n",
    "        </ul>\n",
    "    </font>\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "    <summary><font size=\"3\">output_location_path</font></summary>\n",
    "    <font size=\"2\">The file <code>data/output_object_image_batch.json</code> specifies where the output files will be stored. Sample file has been provided. The user needs to provide the following in this file:\n",
    "        <ul>\n",
    "            <li><code>namespace</code> : Namespace name</li>\n",
    "            <li><code>bucket</code> : Bucket name</li>\n",
    "            <li><code>prefix</code> : Prefix name</li>\n",
    "        </ul>\n",
    "    </font>\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><font size=\"3\">max_results</font></summary>\n",
    "    <font size=\"2\">Provide the maximum number of results needed for image classification. This is an upper limit over the output classes, the API may detect lesser classes according to the image.</font><br>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d5cb024a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_location_path = 'data/input_objects_image_batch.json'\n",
    "output_location_path = 'data/output_object_image_batch.json'\n",
    "max_results = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f578142b",
   "metadata": {},
   "source": [
    "### Authorize user config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9a472d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = oci.config.from_file('~/.oci/config')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf02858",
   "metadata": {},
   "source": [
    "### Load input and output object locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "75b6ba28",
   "metadata": {},
   "outputs": [],
   "source": [
    "compartment_id, input_location = load_input_object_locations(input_location_path)\n",
    "output_location = load_output_object_location(output_location_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e3c644",
   "metadata": {},
   "source": [
    "### Create AI service vision client and image job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3748b57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_service_vision_client = AIServiceVisionClient(config=config)\n",
    "create_image_job_details = CreateImageJobDetails()\n",
    "\n",
    "image_classification_feature = ImageClassificationFeature()\n",
    "image_classification_feature.max_results = max_results\n",
    "features = [image_classification_feature]\n",
    "create_image_job_details.features = features\n",
    "create_image_job_details.compartment_id = compartment_id\n",
    "create_image_job_details.input_location = input_location\n",
    "create_image_job_details.output_location = output_location\n",
    "\n",
    "res = ai_service_vision_client.create_image_job(create_image_job_details=create_image_job_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea31b4d0",
   "metadata": {},
   "source": [
    "### Job submitted\n",
    "The job is created and is in <code>ACCEPTED</code> state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "054a5fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "compartment_id": "ocid1.tenancy.oc1..aaaaaaaa6xo4q4r2l2nvcr3sl657pwla5k3xtbk2s6vgyrvxfuh4p66frooq",
       "features": [
        {
         "feature_type": "IMAGE_CLASSIFICATION",
         "max_results": 5
        }
       ],
       "id": "ocid1.aivisionimagejob.oc1.iad.amaaaaaa74akfsaab7h26dhaczqsn37bmrdufbez37f5dkznf2ofgpcjteza",
       "input_location": {
        "object_locations": [
         {
          "bucket_name": "vision-demo-notebooks",
          "namespace_name": "axhheqi2ofpb",
          "object_name": "car.jpg"
         },
         {
          "bucket_name": "vision-demo-notebooks",
          "namespace_name": "axhheqi2ofpb",
          "object_name": "pole.jpg"
         }
        ],
        "source_type": "OBJECT_LIST_INLINE_INPUT_LOCATION"
       },
       "lifecycle_state": "ACCEPTED",
       "output_location": {
        "bucket_name": "async-demo",
        "namespace_name": "axhheqi2ofpb",
        "prefix": "image_batch_notebook_result"
       },
       "percent_complete": 0,
       "time_accepted": "2021-11-16T05:27:35.038000+00:00"
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "execution_count": 137,
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_json = json.loads(repr(res.data))\n",
    "clean_res = clean_output(res_json)\n",
    "JSON(clean_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724dcc4c",
   "metadata": {},
   "source": [
    "### Job in progress\n",
    "The job progress is tracked till completion with an interval of 5 seconds and is in <code>IN_PROGRESS</code> state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "3d647a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID : ocid1.aivisionimagejob.oc1.iad.amaaaaaa74akfsaab7h26dhaczqsn37bmrdufbez37f5dkznf2ofgpcjteza \n",
      "\n",
      "Job is IN_PROGRESS for 0 seconds\n",
      "Job is IN_PROGRESS for 5 seconds\n",
      "Job is IN_PROGRESS for 10 seconds\n",
      "Job is IN_PROGRESS for 15 seconds\n",
      "Job is IN_PROGRESS for 20 seconds\n",
      "Job is IN_PROGRESS for 25 seconds\n",
      "Job is IN_PROGRESS for 30 seconds\n"
     ]
    }
   ],
   "source": [
    "job_id = res.data.id\n",
    "print(\"Job ID :\", job_id, '\\n')\n",
    "seconds = 0\n",
    "res = ai_service_vision_client.get_image_job(image_job_id=job_id)\n",
    "\n",
    "while res.data.lifecycle_state in [\"IN_PROGRESS\", \"ACCEPTED\"]:\n",
    "    print(\"Job is IN_PROGRESS for \" + str(seconds) + \" seconds\")\n",
    "    time.sleep(5)\n",
    "    seconds += 5\n",
    "    res = ai_service_vision_client.get_image_job(image_job_id=job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04cb915",
   "metadata": {},
   "source": [
    "### Job completed\n",
    "The job is completed and is in <code>SUCCEEDED</code> state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a40d76b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "compartment_id": "ocid1.tenancy.oc1..aaaaaaaa6xo4q4r2l2nvcr3sl657pwla5k3xtbk2s6vgyrvxfuh4p66frooq",
       "features": [
        {
         "feature_type": "IMAGE_CLASSIFICATION",
         "max_results": 5
        }
       ],
       "id": "ocid1.aivisionimagejob.oc1.iad.amaaaaaa74akfsaab7h26dhaczqsn37bmrdufbez37f5dkznf2ofgpcjteza",
       "input_location": {
        "object_locations": [
         {
          "bucket_name": "vision-demo-notebooks",
          "namespace_name": "axhheqi2ofpb",
          "object_name": "car.jpg"
         },
         {
          "bucket_name": "vision-demo-notebooks",
          "namespace_name": "axhheqi2ofpb",
          "object_name": "pole.jpg"
         }
        ],
        "source_type": "OBJECT_LIST_INLINE_INPUT_LOCATION"
       },
       "lifecycle_state": "SUCCEEDED",
       "output_location": {
        "bucket_name": "async-demo",
        "namespace_name": "axhheqi2ofpb",
        "prefix": "image_batch_notebook_result"
       },
       "percent_complete": 100,
       "time_accepted": "2021-11-16T05:27:35.038000+00:00",
       "time_finished": "2021-11-16T05:28:12.795000+00:00",
       "time_started": "2021-11-16T05:27:52.852000+00:00"
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "execution_count": 139,
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_json = json.loads(repr(res.data))\n",
    "clean_res = clean_output(res_json)\n",
    "JSON(clean_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49f1fc2",
   "metadata": {},
   "source": [
    "### Display detected classes\n",
    "The detected classes will be displayed in decreasing order of confidence level for a randomly selected image from the batch input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f8045d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image : car.jpg\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_00e9f2fa_469e_11ec_86c8_0242ac130002 th {\n",
       "          text-align: center;\n",
       "    }#T_00e9f2fa_469e_11ec_86c8_0242ac130002row0_col0,#T_00e9f2fa_469e_11ec_86c8_0242ac130002row0_col1,#T_00e9f2fa_469e_11ec_86c8_0242ac130002row1_col0,#T_00e9f2fa_469e_11ec_86c8_0242ac130002row1_col1,#T_00e9f2fa_469e_11ec_86c8_0242ac130002row2_col0,#T_00e9f2fa_469e_11ec_86c8_0242ac130002row2_col1,#T_00e9f2fa_469e_11ec_86c8_0242ac130002row3_col0,#T_00e9f2fa_469e_11ec_86c8_0242ac130002row3_col1,#T_00e9f2fa_469e_11ec_86c8_0242ac130002row4_col0,#T_00e9f2fa_469e_11ec_86c8_0242ac130002row4_col1{\n",
       "            text-align:  center;\n",
       "        }</style><table id=\"T_00e9f2fa_469e_11ec_86c8_0242ac130002\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Class</th>        <th class=\"col_heading level0 col1\" >Confidence</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_00e9f2fa_469e_11ec_86c8_0242ac130002level0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "                        <td id=\"T_00e9f2fa_469e_11ec_86c8_0242ac130002row0_col0\" class=\"data row0 col0\" >Car</td>\n",
       "                        <td id=\"T_00e9f2fa_469e_11ec_86c8_0242ac130002row0_col1\" class=\"data row0 col1\" >0.992760</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_00e9f2fa_469e_11ec_86c8_0242ac130002level0_row1\" class=\"row_heading level0 row1\" >2</th>\n",
       "                        <td id=\"T_00e9f2fa_469e_11ec_86c8_0242ac130002row1_col0\" class=\"data row1 col0\" >Wheel</td>\n",
       "                        <td id=\"T_00e9f2fa_469e_11ec_86c8_0242ac130002row1_col1\" class=\"data row1 col1\" >0.979060</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_00e9f2fa_469e_11ec_86c8_0242ac130002level0_row2\" class=\"row_heading level0 row2\" >3</th>\n",
       "                        <td id=\"T_00e9f2fa_469e_11ec_86c8_0242ac130002row2_col0\" class=\"data row2 col0\" >Automotive exterior</td>\n",
       "                        <td id=\"T_00e9f2fa_469e_11ec_86c8_0242ac130002row2_col1\" class=\"data row2 col1\" >0.971239</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_00e9f2fa_469e_11ec_86c8_0242ac130002level0_row3\" class=\"row_heading level0 row3\" >4</th>\n",
       "                        <td id=\"T_00e9f2fa_469e_11ec_86c8_0242ac130002row3_col0\" class=\"data row3 col0\" >Vehicle registration plate</td>\n",
       "                        <td id=\"T_00e9f2fa_469e_11ec_86c8_0242ac130002row3_col1\" class=\"data row3 col1\" >0.963289</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_00e9f2fa_469e_11ec_86c8_0242ac130002level0_row4\" class=\"row_heading level0 row4\" >5</th>\n",
       "                        <td id=\"T_00e9f2fa_469e_11ec_86c8_0242ac130002row4_col0\" class=\"data row4 col0\" >Building</td>\n",
       "                        <td id=\"T_00e9f2fa_469e_11ec_86c8_0242ac130002row4_col1\" class=\"data row4 col1\" >0.951315</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f06073ecfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "object_storage_client = oci.object_storage.ObjectStorageClient(config)\n",
    "\n",
    "index = randint(0, len(input_location.object_locations) - 1)\n",
    "object_location = input_location.object_locations[index]\n",
    "\n",
    "output_object_name = output_location.prefix + \"/\" + res.data.id + \"/\" + \\\n",
    "        object_location.namespace_name  + \"_\" + object_location.bucket_name + \"_\" + \\\n",
    "            object_location.object_name\n",
    "\n",
    "res_json = object_storage_client.get_object(output_location.namespace_name, \\\n",
    "    output_location.bucket_name, object_name = output_object_name+\".json\").data.content\n",
    "res_dict = json.loads(res_json)\n",
    "\n",
    "print(\"Image :\", object_location.object_name)\n",
    "if res_dict['labels'] is not None:\n",
    "    display_classes(res_dict['labels'])\n",
    "else:\n",
    "    print(\"No image classes detected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df28ffd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fc0997",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
