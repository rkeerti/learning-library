{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41cd676b",
   "metadata": {},
   "source": [
    "# <b>Document text detection batch feature demo</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9616eccb",
   "metadata": {},
   "source": [
    "The AIServiceVisionClient offers the document text detection feature in batch mode. This notebook aims to provide overall clarity about the feature to the user in terms of requirements, usage and the output of the batch i.e. asynchronous API.<br>\n",
    "<ul>\n",
    "    <li>The output response files are stored at the object storage specified in <code>data/output_object_document_batch.json</code>. </li>\n",
    "<li>The detected text for a randomly selected document from the batch input is displayed in the last section of the notebook.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac5f5b0",
   "metadata": {},
   "source": [
    "### Steps to run the notebook:\n",
    "<details>\n",
    "    <summary>Notebook session setup</summary>\n",
    "    <ol>\n",
    "        <li><font size=\"2\">Installing the OCI Vision SDK</font></li>\n",
    "        <li><font size=\"2\">Installing other dependencies</font></li>\n",
    "        <li><font size=\"2\">Setup sample input documents</font></li>\n",
    "        <li><font size=\"2\">Setup helper .py files</font></li>\n",
    "    </ol>\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "    <summary>Importing the required modules</summary>\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "    <summary>Setting the input variables</summary>\n",
    "     <font size=\"2\">The user can change the input variables, if necessary. They have been assigned default values.</font>\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "    <summary>Running the main pipeline</summary>\n",
    "    <font size=\"2\">Run all cells to get the output in the <code>output</code> directory. </font><br>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50b0e60",
   "metadata": {},
   "source": [
    "### Notebook session setup\n",
    "<details>\n",
    "    <summary>Instructions</summary>\n",
    "    <ul>\n",
    "        <li><font size=\"2\">The user needs to setup only once.</font></li>\n",
    "        <li><font size=\"2\">Uncomment the commented cells and run once to setup.</font></li>\n",
    "        <li><font size=\"2\">Comment back the same cells to avoid running again.</font></li>\n",
    "    </ul>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc476250",
   "metadata": {},
   "source": [
    "#### Installing the OCI Vision SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4fe3a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget \"https://objectstorage.us-ashburn-1.oraclecloud.com/n/axhheqi2ofpb/b/vision-demo-notebooks/o/vision_service_python_client-0.3.45-py2.py3-none-any.whl\"\n",
    "# !pip install vision_service_python_client-0.3.45-py2.py3-none-any.whl\n",
    "# !rm vision_service_python_client-0.3.45-py2.py3-none-any.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addcca95",
   "metadata": {},
   "source": [
    "#### Installing other dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02dbc26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install matplotlib==3.3.4\n",
    "# !pip install pandas==1.1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d932093",
   "metadata": {},
   "source": [
    "#### Setup sample input documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7deaab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget \"https://objectstorage.us-ashburn-1.oraclecloud.com/n/axhheqi2ofpb/b/vision-demo-notebooks/o/input_objects_document_batch.json\"\n",
    "# !wget \"https://objectstorage.us-ashburn-1.oraclecloud.com/n/axhheqi2ofpb/b/vision-demo-notebooks/o/output_object_document_batch.json\"\n",
    "# !mkdir data\n",
    "# !mv input_objects_document_batch.json data\n",
    "# !mv output_object_document_batch.json data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dc7c06",
   "metadata": {},
   "source": [
    "#### Setup helper .py files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5c0b4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget \"https://objectstorage.us-ashburn-1.oraclecloud.com/n/axhheqi2ofpb/b/vision-demo-notebooks/o/analyze_document_batch_utils.py\"\n",
    "# !mkdir helper\n",
    "# !mv analyze_document_batch_utils.py helper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e354c71f",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83e2e09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import io\n",
    "from random import randint\n",
    "import oci\n",
    "\n",
    "from vision_service_python_client.models import output_location\n",
    "from vision_service_python_client.ai_service_vision_client import AIServiceVisionClient\n",
    "from vision_service_python_client.models.create_document_job_details import CreateDocumentJobDetails\n",
    "from vision_service_python_client.models.document_text_detection_feature import DocumentTextDetectionFeature\n",
    "from helper.analyze_document_batch_utils import load_input_object_locations, load_output_object_location, display_classes, clean_output\n",
    "from IPython.display import JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713038ca",
   "metadata": {},
   "source": [
    "### Set input variables\n",
    "<details>\n",
    "    <summary><font size=\"3\">input_location_path</font></summary>\n",
    "    <font size=\"2\">The file <code>data/input_objects_document_batch.json</code> specifies where the input documents are to be taken from. Sample files have been provided. The user needs to provide the following in this file:\n",
    "        <ul>\n",
    "            <li><code>compartment_id</code> : Compartment ID</li>\n",
    "            <li><code>input_objects</code>: List with the object locations in the following format-</li>\n",
    "            <ul>\n",
    "                <li><code>namespace</code> : Namespace name</li>\n",
    "                <li><code>bucket</code> : Bucket name</li>\n",
    "                <li><code>objects</code> : List of object names</li>\n",
    "            </ul>\n",
    "        </ul>\n",
    "    </font>\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "    <summary><font size=\"3\">output_location_path</font></summary>\n",
    "    <font size=\"2\">The file <code>data/output_object_document_batch.json</code> specifies where the output files will be stored. Sample files have been provided. The user needs to provide the following in this file:\n",
    "        <ul>\n",
    "            <li><code>namespace</code> : Namespace name</li>\n",
    "            <li><code>bucket</code> : Bucket name</li>\n",
    "            <li><code>prefix</code> : Prefix name</li>\n",
    "        </ul>\n",
    "    </font>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da0f14ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_location_path = 'data/input_objects_document_batch.json'\n",
    "output_location_path = 'data/output_object_document_batch.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e4c346",
   "metadata": {},
   "source": [
    "### Authorize user config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e1ed1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = oci.config.from_file('~/.oci/config')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7075ee45",
   "metadata": {},
   "source": [
    "### Load input and output object locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60112f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "compartment_id, input_location = load_input_object_locations(input_location_path)\n",
    "output_location = load_output_object_location(output_location_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21dad48f",
   "metadata": {},
   "source": [
    "### Create AI service vision client and document job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77a93e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_service_vision_client = AIServiceVisionClient(config=config)\n",
    "create_document_job_details = CreateDocumentJobDetails()\n",
    "\n",
    "document_text_detection_feature = DocumentTextDetectionFeature()\n",
    "features = [document_text_detection_feature]\n",
    "create_document_job_details.features = features\n",
    "create_document_job_details.compartment_id = compartment_id\n",
    "create_document_job_details.input_location = input_location\n",
    "create_document_job_details.output_location = output_location\n",
    "\n",
    "res = ai_service_vision_client.create_document_job(create_document_job_details=create_document_job_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8f336d",
   "metadata": {},
   "source": [
    "### Job submitted\n",
    "The job is created and is in <code>ACCEPTED</code> state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56bdb203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "compartment_id": "ocid1.tenancy.oc1..aaaaaaaa6xo4q4r2l2nvcr3sl657pwla5k3xtbk2s6vgyrvxfuh4p66frooq",
       "features": [
        {
         "feature_type": "TEXT_DETECTION"
        }
       ],
       "id": "ocid1.aivisiondocumentjob.oc1.iad.amaaaaaa74akfsaa7svtdsbcb4cbc75bqbwzxnubfdj3oojstcmrd5vj7kta",
       "input_location": {
        "object_locations": [
         {
          "bucket_name": "vision-demo-notebooks",
          "namespace_name": "axhheqi2ofpb",
          "object_name": "TextDetection.pdf"
         }
        ],
        "source_type": "OBJECT_LIST_INLINE_INPUT_LOCATION"
       },
       "lifecycle_state": "ACCEPTED",
       "output_location": {
        "bucket_name": "async-demo",
        "namespace_name": "axhheqi2ofpb",
        "prefix": "document_batch_notebook_result"
       },
       "percent_complete": 0,
       "time_accepted": "2021-11-16T05:35:11.423000+00:00"
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_json = json.loads(repr(res.data))\n",
    "clean_res = clean_output(res_json)\n",
    "JSON(clean_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc49877",
   "metadata": {},
   "source": [
    "### Job in progress\n",
    "The job progress is tracked till completion with an interval of 5 seconds and is in <code>IN_PROGRESS</code> state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57ff9a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID : ocid1.aivisiondocumentjob.oc1.iad.amaaaaaa74akfsaa7svtdsbcb4cbc75bqbwzxnubfdj3oojstcmrd5vj7kta \n",
      "\n",
      "Job is IN_PROGRESS for 0 seconds\n",
      "Job is IN_PROGRESS for 5 seconds\n",
      "Job is IN_PROGRESS for 10 seconds\n",
      "Job is IN_PROGRESS for 15 seconds\n",
      "Job is IN_PROGRESS for 20 seconds\n",
      "Job is IN_PROGRESS for 25 seconds\n",
      "Job is IN_PROGRESS for 30 seconds\n",
      "Job is IN_PROGRESS for 35 seconds\n",
      "Job is IN_PROGRESS for 40 seconds\n",
      "Job is IN_PROGRESS for 45 seconds\n",
      "Job is IN_PROGRESS for 50 seconds\n",
      "Job is IN_PROGRESS for 55 seconds\n",
      "Job is IN_PROGRESS for 60 seconds\n",
      "Job is IN_PROGRESS for 65 seconds\n",
      "Job is IN_PROGRESS for 70 seconds\n",
      "Job is IN_PROGRESS for 75 seconds\n",
      "Job is IN_PROGRESS for 80 seconds\n",
      "Job is IN_PROGRESS for 85 seconds\n"
     ]
    }
   ],
   "source": [
    "job_id = res.data.id\n",
    "print(\"Job ID :\", job_id, '\\n')\n",
    "seconds = 0\n",
    "res = ai_service_vision_client.get_document_job(document_job_id=job_id)\n",
    "\n",
    "while res.data.lifecycle_state in [\"IN_PROGRESS\", \"ACCEPTED\"]:\n",
    "    print(\"Job is IN_PROGRESS for \" + str(seconds) + \" seconds\")\n",
    "    time.sleep(5)\n",
    "    seconds += 5\n",
    "    res = ai_service_vision_client.get_document_job(document_job_id=job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e90f53",
   "metadata": {},
   "source": [
    "### Job completed\n",
    "The job is completed and is in <code>SUCCEEDED</code> state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "346bb26b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "compartment_id": "ocid1.tenancy.oc1..aaaaaaaa6xo4q4r2l2nvcr3sl657pwla5k3xtbk2s6vgyrvxfuh4p66frooq",
       "features": [
        {
         "feature_type": "TEXT_DETECTION"
        }
       ],
       "id": "ocid1.aivisiondocumentjob.oc1.iad.amaaaaaa74akfsaa7svtdsbcb4cbc75bqbwzxnubfdj3oojstcmrd5vj7kta",
       "input_location": {
        "object_locations": [
         {
          "bucket_name": "vision-demo-notebooks",
          "namespace_name": "axhheqi2ofpb",
          "object_name": "TextDetection.pdf"
         }
        ],
        "source_type": "OBJECT_LIST_INLINE_INPUT_LOCATION"
       },
       "lifecycle_state": "SUCCEEDED",
       "output_location": {
        "bucket_name": "async-demo",
        "namespace_name": "axhheqi2ofpb",
        "prefix": "document_batch_notebook_result"
       },
       "percent_complete": 100,
       "time_accepted": "2021-11-16T05:35:11.423000+00:00",
       "time_finished": "2021-11-16T05:36:40.269000+00:00",
       "time_started": "2021-11-16T05:35:29.488000+00:00"
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_json = json.loads(repr(res.data))\n",
    "clean_res = clean_output(res_json)\n",
    "JSON(clean_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6e34ec",
   "metadata": {},
   "source": [
    "### Display detected text\n",
    "The detected text will be displayed for a randomly selected document from the batch input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f63578b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document : TextDetection.pdf \n",
      "\n",
      "**************** PAGE NO. 1 ****************\n",
      "\n",
      "ORACLE\n",
      "12€\n",
      "DATABASE\n",
      "Big Data Analytics with Oracle Advanced Analytics\n",
      "Making Big Data and Analytics Simple\n",
      "O R A C L E W H I T E P A P E R\n",
      "|\n",
      "J U L Y 2 0 1 5\n",
      "ORACLE®\n",
      "\n",
      "\n",
      "**************** PAGE NO. 2 ****************\n",
      "\n",
      "Disclaimer\n",
      "The following is intended to outline our general product direction. It is intended for information\n",
      "purposes only, and may not be incorporated into any contract. It is not a commitment to deliver any\n",
      "material, code, or functionality, and should not be relied upon in making purchasing decisions. The\n",
      "development, release, and timing of any features or functionality described for Oracle's products\n",
      "remains at the sole discretion of Oracle.\n",
      "BIG DATA ANALYTICS WITH ORACLE ADVANCED ANALYTICS\n",
      "\n",
      "\n",
      "**************** PAGE NO. 3 ****************\n",
      "\n",
      "Table of Contents\n",
      "Disclaimer\n",
      "Executive Summary: Big Data Analytics with Oracle Advanced Analytics\n",
      "Big Data and Analytics-New Opportunities and New Challenges\n",
      "3\n",
      "Predictive Analytics!\n",
      "3\n",
      "Move the Algorithms, Not the Data\n",
      "4\n",
      "SQL and R Support\n",
      "5\n",
      "In-Database Processing with Oracle Advanced Analytics\n",
      "6\n",
      "Oracle Data Miner Workflow GUI; a SQL Developer extension\n",
      "8\n",
      "Oracle R Enterprise-Integrating Open Source R with the Oracle Database\n",
      "9\n",
      "Hadoop, Oracle Big Data Appliance and Big Data SQL\n",
      "11\n",
      "A Platform for Developing Enterprise-wide Predictive Analytics Applications\n",
      "12\n",
      "Conclusion\n",
      "14\n",
      "BIG DATA ANALYTICS WITH ORACLE ADVANCED ANALYTICS\n",
      "\n",
      "\n",
      "**************** PAGE NO. 4 ****************\n",
      "\n",
      "\"Essentially, all models are wrong, …but some are useful.\"\n",
      "GEORGE BOX\n",
      "FAMOUS TWENTIETH CENTURY STATISTICIAN\n",
      "Executive Summary: Big Data Analytics with Oracle Advanced Analytics\n",
      "The era of \"big data\" and the \"cloud\" are driving companies to change. Just to keep pace, they must\n",
      "leam new skills and implement new practices that leverage those new data sources and technologies.\n",
      "improved customer interactions and greater perceived value are pushing companies forward. Big data\n",
      "and analytics offer the promise to satisfy these new requirements. Cloud, competition, big data\n",
      "analytics and next-generation \"predictive\" applications are driving companies towards achieving new\n",
      "goals of delivering improved \"actionable insights\" and better outcomes. Traditional BI & Analytics\n",
      "approaches don't deliver these detailed predictive insights and simply can't satisfy the emerging\n",
      "customer expeciations in this new world order created by big data and the cloud.\n",
      "Unfortunately, with big data, as the data grows and expands in the three V's; velocity volume and\n",
      "variety (data types), new problems emerge. Data volumes grow and data becomes unmanageable\n",
      "and immovable. Scalability, security, and information latency become new issues. Dealing with\n",
      "unstructured data, sensor data and spatial data all introduce new data type complexities.\n",
      "Traditional advanced analytics has several information technology inherent weak points: data extracts\n",
      "and data movement, data duplication resulting in no single-source of truth, data security exposures,\n",
      "separate and many times, depending on the skills of the data analysts/scientists involved, multiple\n",
      "analytical tools (commercial and open source) and languages (SAS, R, SQL, Python, SPSS, etc.).\n",
      "Problems become particularly egregious during a deployment phase when the worlds of data analysis\n",
      "and information management collide.\n",
      "exported to separate analytical servers and tools (SAS, R. Python, SPSS, etc.) that have been\n",
      "especially designed for statisticians and data scientists to analyze data. The analytics they perform\n",
      "range from simple descriptive statistical analysis to advanced, predictive and prescriptive analytics. If\n",
      "a data scientist builds a predictive model that is determined to be useful and valuable, then IT needs to\n",
      "1 | BIG DATA ANALYTICS WITH ORACLE ADVANCED ANALYTICS\n",
      "\n",
      "\n",
      "**************** PAGE NO. 5 ****************\n",
      "\n",
      "be involved to figure out deployment and enterprise deployment and application integration issues\n",
      "become the next big challenge. The predictive model(s)-and all its associated data preparation and\n",
      "transformation steps-have to be somehow translated to SQL and recreated inside the database in\n",
      "order to apply the models and make predictions on the larger datassts maintained inside the data\n",
      "warehouse. This model translation phase introduces tedious, time consuming and expensive manual\n",
      "coding steps from the original statistical language (SAS, R, and Python) into SQL. DBAs and IT must\n",
      "somehow \"productionize\" these separate statistical models inside the database and/or data warehouse\n",
      "for distribution throughout the enterprise. Some vendors will charge for specialized products and\n",
      "options for just for predictive model deployment. This is where many advanced analytics projects fail.\n",
      "Add Hadoop, sensor data, tweets, and expanding big data reservoirs and the entire \"dafa to actionable\n",
      "insights\" process becomes more challenging.\n",
      "Not with Oracle. Oracle delivers a big data and analytics platform that eliminates the traditional\n",
      "extract, move, load, analyze, export, move load paradigm. With Oracle Database 12c and the Oracle\n",
      "Advanced Analytics Option, big data management and big data analytics are designed into the data\n",
      "management platform from the beginning. Oracle's multiple decades of R&D investment in developing\n",
      "the industry's leading data management platform, Oracle SQL, Big Data SQL, Oracle Exadata, Oracle\n",
      "Big Data Appliance and integration with open source R are seamlessly combined and integrated into a\n",
      "single platform-the Oracle Database.\n",
      "Oracle's vision is a big data and analytic\n",
      "platform for the era of big data and cloud to:\n",
      "Make big data and analytics simple\n",
      "(for any data size, on any computer\n",
      "infrastructure and any variety of data, in any\n",
      "combination) and\n",
      "Make big data and analytics deployment\n",
      "simple (as a service, as a platform, as an\n",
      "application)\n",
      "Crade Advanced Anslytics da mveet and obines big mantwith big a anayics.\n",
      "Oracle Advanced Analytics offers a wide library of powerful in-database algorithms and integration with\n",
      "2 | BIG DATA ANALYTICS WITH ORACLE ADVANCED ANALYTICS\n",
      "\n",
      "\n",
      "**************** PAGE NO. 6 ****************\n",
      "\n",
      "open source R that together can solve a wide variety of business problems and can be accessed via\n",
      "SQL, R or GUL. Oracle Advanced Analytics, an option to the Oracle Database Enterprise Edition 12c,\n",
      "extends the database into an enterprise-wide analytical platform for data-driven problems such as\n",
      "churn prediction, customer segmentation, fraud and anomaly detection, identifying cross-sell and up-\n",
      "sell opportunities, market basket analysis, and text mining and sentiment analysis. Oracle Advanced\n",
      "Analytics empowers data analyst, data scientists and business analysts to more extract knowledge,\n",
      "discover new insights and make informed predictions-working directly with large data volumes in the\n",
      "Oracle Database.\n",
      "Data analysts/scientists have choice and flexibility in how they interact with Oracle Advanced\n",
      "Analytics. Oracle Data Miner is an Oracle SQL Developer extension designed for data analysts that\n",
      "provides an easy to use \"drag and drop\" workflow GUI to the Oracle Advanced Analytics SQL data\n",
      "mining functions (Oracle Data Mining). Oracle SQL Developer is a free integrated development\n",
      "environment that simplifies the development and management of Oracle Database in both traditional\n",
      "and Cloud deployments. When Oracle Data Miner users are satisfied with their analytical\n",
      "methodologies, they can share their workflows with other analysts and/or generate SQL scripts to hand\n",
      "to their DBAs to accslerate model deployment. Oracle Data Miner also provides a PLSQL API for\n",
      "workflow scheduling and automation.\n",
      "R programmers and data scientists can use the familiar open source R statistical programming\n",
      "language console, RStudio or any IDE to work directly with data inside the database and leverage\n",
      "Oracle Advanced Analytics' R integration with the databass (Oracle R Enterprise). Oracle Advanced\n",
      "Analytics' Oracle R Enterprise provides transparent SQL to R translation to equivalent SQL and Oracle\n",
      "Data Mining functions for in-database performance, parallelism, and scalability-this making R ready\n",
      "for the enterprise.\n",
      "Application developers, using the ODM SQL data mining functions and ORE R integration can build\n",
      "completely automated predictive analytic solutions that leverage the strengths of the database and the\n",
      "flexibly of R to integrate Oracle Advanced Analytics analytical solutions into BI dashboards and\n",
      "enterprise applications.\n",
      "By integrating big data management and big data analytics into the same powerful Oracle Database\n",
      "12c data management platform, Oracle eliminates data movement, reduces total cost of ownership\n",
      "and delivers the fastest way to deliver enterprise-wide predictive analytics solutions and applications.\n",
      "2 | BIG DATA ANALYTICS WITH ORACLE ADVANCED ANALYTICS\n",
      "\n",
      "\n",
      "**************** PAGE NO. 7 ****************\n",
      "\n",
      "Big Data and Analytics-New Opportunities and New Challenges\n",
      "Gartner characterizes big data as: \"high volume, velocity, and/or variety information assets that demand new,\n",
      "innovative forms of processing for enhanced decision making, business insights or process optimization.\" However\n",
      "for many, this is not new. Companies have been data mining large volumes of data for years. What's been new\n",
      "and more challenging is the increasing pace of the \"big data\" volumes, velocities and varieties of sources coupled\n",
      "with new customer expectations of what new *actionable insights\" can be achieved. This places new demands on\n",
      "Information Technology (IT) departments, data scientist and data analysts and the departments and lines of\n",
      "Unfortunately, as big data grows and expands over time in its three V's; velocity, volume and variety, new problems\n",
      "emerge. Data volumes grow and eventually become near immovable. Eventually at some point, it becomes\n",
      "impractical to move large data amounts to separate servers for the data analysis. During the big data explosion,\n",
      "many problems are experienced such as data movement, data duplication, security, creation of \"data analysis\n",
      "sprawl-marts\", separation of data management from data analysis and worse, information latency expands,\n",
      "oftentimes to multiple days and weeks.\n",
      "Traditional data analysis methods contribute to these problems. Data analysts and data scientist typically have their\n",
      "own special \"tools\" that they've leamed to use (SAS, R, SPSS or Python, etc.) so require data extracts from the\n",
      "database /data warehouse, transforms and loads to dedicated, separate analytical servers. If a data scientist builds\n",
      "a good rdicive mode, th nwroble erges. Deployment of ta oere awhen itis most\n",
      "needed and integration into applications e.g. Bl dashboards, call centers, websites, ATMs and mobile devices\n",
      "becomes the next big challenge for IT. The predictive model(s)-and all the associated data preparation and\n",
      "transformation steps--have to be recreated in the destination platform to make the predictions on the larger data\n",
      "tables. For Oracle nviroments, this export data anaysis mpot resuts otr loop complicates t data analysis\n",
      "unsosssarily and introducss the time consuming and expansive mod deloyment phase. IT is asked to\n",
      "\"productionize\" the models and re-implement them using SQL inside the database.\n",
      "The challenge is that the models were originally created using a statistical programming language (SAS, R, SPSS\n",
      "and Python.) but to productionize them, they must run as SQL functions inside the database. This is where the big\n",
      "time sink occurs and errors can be introduced. For organizations who strive to be leaders, efficient data collection,\n",
      "data management, analysis, and deployment of predictive models, insights and actionable business intelligence are\n",
      "the keys to their success. Traditional data analysis methods just won't suffice. Add Hadoop, sensor data, tweets,\n",
      "and ever expanding new data reservoirs and the whole problem just gets worse.\n",
      "Predictive Analytics!\n",
      "Predictive analytics is the process of automatically sifting through large amounts of data to find previously hidden\n",
      "patterns, discover valuable new insights and make informed predictions for data-driven problems such as:\n",
      "Predicting customer behaviors, identifying cross-selling and up-selling opportunities\n",
      "Anticipating customer chum, employee attrition and student retention\n",
      "Detecting anomalies and combating potential tax, medical or expense fraud,\n",
      "Understanding hidden customer segments and understanding customer sentiment,\n",
      "Identifying key factors that drive outcomes and delivering improved quality\n",
      "3 | BIG DATA ANALYTICS WITH ORACLE ADVANCED ANALYTICS\n",
      "\n",
      "\n",
      "**************** PAGE NO. 8 ****************\n",
      "\n",
      "Predictive Analytics as a technology has been delivering measurable value for years. Predictive Analytics climbed\n",
      "it's was up Gartner's Hyp Cyle for Emerging Toogis and reached the Gartner's nviable plateu of\n",
      "productivity\" in 2013. Today in 2015, predictive analytics are being implemented and deployed in enterprises and\n",
      "applications ranging from predicting churn and employee turnover, to flagging medical fraud and tax non-compliance\n",
      "to targeted selling and real-time recommendation engines. As big data analytics technologies and user adoptions\n",
      "evolve, mature and expand, predictive analytics use cases and integrated \"predictive\" applications that push \"the art\n",
      "of the possible\" are emerging every day and are constantly raising the bar of new user expectations.\n",
      "Oracle Advanced Analytics provides support for these data driven problems by offering a wide range of powerful\n",
      "workhorse data mining algorithms that have been implemented in a relational database environment (RDBMS)\n",
      "Algorithms are implemented as SQL functions inside the database. Oracle Advanced Analytics' data mining\n",
      "algorithms hence leverage all related SQL features and can mine data in its original star schema representation\n",
      "including standard structured tables and views, transactional data and aggregations, unstructured i.e. CLOB data\n",
      "types (using Oracle Text to parse out \"tokens\") and spatial data. Oracle Advanced Analytics in-database SQL data\n",
      "mining functions take advantage of parallelism inside the database for both model build and model apply, honor all\n",
      "security and user privilege schemes, adhere to revision control and audit tracking database features and can mine\n",
      "data in its native and potentially encrypted form inside the Oracle Database.\n",
      "OAA In-Database Data Mining Algorithms-SQL & R & GUI Access\n",
      "Function\n",
      "Algorithms\n",
      "Applicability\n",
      "Logistic Regression (GLM)\n",
      "Classical statistical technique\n",
      "Classification\n",
      "Decision Trees\n",
      "Popular / Rules / tramsparency\n",
      "Naive Bayes\n",
      "Support Vector Machines (SVM)\n",
      "Embedded app\n",
      "Wide / narrow data/ text\n",
      "Regrestion\n",
      "Linear Regression (GLM)\n",
      "Support Vector Machine (SVM)\n",
      "Classical statistical technique\n",
      "Wide / narrow data/ text\n",
      "Ancmaly\n",
      "One Class SVM\n",
      "Detection\n",
      "Unknown fraud cases or anomalies\n",
      "Attribute\n",
      "Minimum Description Length (MDL)\n",
      "Importance\n",
      "Principal Components Analysis (PCA)\n",
      "Attribute reduction, Reduce data noise\n",
      "Astociation\n",
      "Aeciori\n",
      "Rules\n",
      "Marker basket analysis / Nest Best Offer\n",
      "Hierarchicalk-Means\n",
      "Clustering\n",
      "HierarchicalO-Claster\n",
      "Product grouping/ Text mining\n",
      "Expectation-Maximization Clustering (EM)\n",
      "Gene and protein analysis\n",
      "Feature\n",
      "Nornegative Matrie Factoritation (NME)\n",
      "Extraction\n",
      "Singular Value Decompostion (SVD)\n",
      "Text analysis / Feature reduction\n",
      "Crace Advance Arayics 12 daing con ar mmned c e acedby SL, PSL, R\n",
      "and the Oracle Data Miner GUL\n",
      "Move the Algorithms, Not the Data\n",
      "Data is big: algorithms are small. Hence, it makes logical sense to move the algonithms to the data rather than\n",
      "moving the data to the algonithms. Oracle realized this big data and analytics data challenge in 1999 when it\n",
      "acquired Thinking Machins Corporion's dat ming cholog and development eam. At th ime Cracle\n",
      "commenced on a strategy to develop traditional and cutting edge machine learning algorithms and statistical\n",
      "functions as native SQL functions with full SQL language support. With Oracle Advanced Analytics, data mining\n",
      "4 | BIG DATA ANALYTICS WITH ORACLE ADVANCED ANALYTICS\n",
      "\n",
      "\n",
      "**************** PAGE NO. 9 ****************\n",
      "\n",
      "algorithms run as native L funcions o as PSL scis, callout o ensibitmwork addins. Modals\n",
      "are first class database objects that can be built, applied, shared, and audited.\n",
      "In the early 2000's, starting in Oracle Data Mining Release 9.2, Oracle's first data mining algorithms took advantage\n",
      "of available core Database's strengths-specifically, counting, parallielism, scalability and other database\n",
      "architectural underpinnings. Essentially, the first two Oracle data mining algorithms, Naive Bayes and A Priori\n",
      "algorithms, are based on counting principles. They count everything very quickly and then assemble conditional\n",
      "probability prediiv moal 100 isi the databse. Nther the data te prediiv meso te resuls\n",
      "ever leave the database.\n",
      "OAA Nalive Bayes algorithm can quickly builds predictive models to predict e.g., \"Who will churn?\", \"Which\n",
      "customers are most likely to purchase Product A?\", or \"What is the probability that an item will fail?\" Let's take an\n",
      "example in a bit more detail for comprehension. Let's say we are interested in selling Product A (e.g. a motorcycle\n",
      "or $500 shoes, etc.). The Oracle Advanced Analytics data mining algorithms, specifically the Naive Bayes\n",
      "algorithm, of all the customers who purchased Product A, it counts how many customers were male vs. female\n",
      "How many rent an apartment vs. owns their own home? How many have children and how many? Each of these\n",
      "predicts whom we should target to increase our likelihood of selling more of Product A.\n",
      "OAA's A Priori \"market basket analysis\" algorithm counts items in each customer's transactional \"baskets\" while\n",
      "looking for co-occurring items e.g. A + B appear together frequently, and then provides conditional probability AR\n",
      "rules. For example:\n",
      "IF, \"Cereal\"' AND \"Bananas\" appear in the same customer's basket,\n",
      "THEN, the \"Milk\" is also likely to appear in the basket.\n",
      "WITH Confidence = 87%, and Support = 11%.\n",
      "Armed with these types of new customer insights from Oracle Advanced Analytics, a store could decide to place the\n",
      "milk near the cereal and bananas, offer new promotional \"breakfast kit\" product bundles or make real-time customer\n",
      "specific recommendations as the customer checks-out. This is just a simple example of the types of ways that big\n",
      "data analytics can find \"actionable insights\" from data. Obviously, more data, more advanced analytics\n",
      "methodologies and fast enterprise wide deployment can open new doors to many new big data and analytics\n",
      "applications and solutions possibilities.\n",
      "SQL and R Support\n",
      "Where SQL is the standard language for data management and has been for 40+ years, for data analysis, various\n",
      "languages compete-R, SAS, Python and SQL and others. SAS, S+, SQL, SPSS and Matlab have been long time\n",
      "favorites, but in recent past years, open source R especially has surged to the top of the pack and Python and\n",
      "others have emerged. Per the KDD Nuggets data mining industry community annual polls\n",
      "(http/www.kdnuggets.com/polls/). R and SQL currently compete for #1 and #2 positions, respectively.\n",
      "The goo news is that Oracle Advanced Anaics supports both guagSL and R. There alegions of\n",
      "developers who know SQL for data management and Oracle provides support for data mining and advanced\n",
      "analytics via Oracle Advanced Analytics' SQL data mining functions and provides tight, industry leading integration\n",
      "with open source R statistical programming language.\n",
      "Most Oracle customers are very familiar with SQL as a language for query, reporting, and analysis of structured\n",
      "data. It is the de facto standard for analysis and the technology that underlies most BI tools. R is a widely popular\n",
      "open source programming language for statistical analysis that is free and because of that is taught in most data\n",
      "& | BIG DATA ANALYTICS WITH ORACLE ADVANCED ANALYTICS\n",
      "\n",
      "\n",
      "**************** PAGE NO. 10 ****************\n",
      "\n",
      "science educational programs. A growing number of data analysts, data scientists, researchers, and academics start\n",
      "by learning to use R, leading to a growing pool of R programmers who can now work with their data inside the\n",
      "Oracle Database using either SQL or R languages,\n",
      "Over the past decade and one-half, Oracle Advanced Analytics has matured and has been developed to now in\n",
      "Oracle 12c, the Cracle Advanced Analytics Option delivers nearly twenty scalable, parallelized, in-database\n",
      "implementations of workhorse predictive analytics algorithms. Oracle Advanced Analytics exposes these data\n",
      "mining algorithms as SQL functions that are accessible via SQL, R language and the Oracle Data Miner GUI, an\n",
      "extension to racle SQL Developer for the mscommn dat driven problems .g ustering regression,\n",
      "prediction, associations, text mining, associations analysis, etc. All Oracle Advanced Analytics algorithms are\n",
      "implemented deep inside the database and take full advantage of the Oracle Database's industry leading scalability,\n",
      "security, SQL functions, integration, ETL, Cloud, structured, unstructured and spatial data types features and\n",
      "strengths and can be accessed via both SQL and R-and GUI.\n",
      "Hence, you can think of Cracle Advanced Analytics like this...\n",
      "Traditional SQL\n",
      "Oracle Advanced Analytics (SQL & R)\n",
      "\"Human-driven\" queries\n",
      "Automated knowledge discovery, model\n",
      "Domain expertise\n",
      "building and deployment\n",
      "Any \"rules\" must be defined and\n",
      "Domain expertise to assemble the \"right\"\n",
      "managed\n",
      "data to mine/analyze\n",
      "SQL Queries\n",
      "Analytical SQL \"Verbs\"\n",
      "SELECT\n",
      "+\n",
      "PREDICT\n",
      "DISTINCT\n",
      "DETECT\n",
      "AGGREGATE\n",
      "CLUSTER\n",
      "WHERE\n",
      "CLASSIFY\n",
      "HO OINV -\n",
      "SSTHIH -\n",
      "-GROUP BY\n",
      "3TLaONE -\n",
      "ORDER BY\n",
      "IDENTIFY FACTORS\n",
      "RANK\n",
      "- ASSOCIATE\n",
      "Orade Advanced Anslytics exends the SOL language to add owr analytical verbs .g predi delect assciae cluster.\n",
      "In-Database Processing with Oracle Advanced Analytics\n",
      "Oracle Advanced Analytics extends the database into a comprehensive advanced analytics platform for big data\n",
      "analytics. With Oracle, powerful analytics are performed directly on data in the database. Results, insights, and real-\n",
      "time predictive models are available and managed by the database.\n",
      "A data mining model is a schema object in the database, built via a PL/SQL API that prepares the data, learns the\n",
      "hidden pattes to build a AA mod which can the be soored via built-in AA data mining SOL functions. When\n",
      "indexes, aggregation techniques) and additional developed new Oracle Advanced Analytics and Oracle Database\n",
      "technologies (e.g., recursion within the parallel infrastructure, IEEE float, automatic data preparation for binning,\n",
      "handling missing values, support for unstructured data i.e. text, etc.).\n",
      "The true power of embedding data mining functions within the database as SQL functions is most evident when\n",
      "scoring data mining models. Once the models have been built by learning the hidden patterns in the historical data\n",
      "6 | BIG DATA ANALYTICS WITH ORACLE ADVANCED ANALYTICS\n",
      "\n",
      "\n",
      "**************** PAGE NO. 11 ****************\n",
      "\n",
      "applying the models to new data inside the database is blazingly fast. Scoring is then just a row-wise function.\n",
      "Hance, rac Advanced Analyics can score many millins of cords in seconds and is designed to support\n",
      "online transactional processing (OLTP) environments.\n",
      "Using Exadata's \"smart scan\" technology it gets better. With Oracle Advanced Analytics running in an Exadata\n",
      "environment, SQL predicates and OAA predictive models get pushed down to the hardware layer for execution.\n",
      "For Oracle Exadata environments, pushed to Exadata storage level for execution\n",
      "For Oracle Big Data Appliance (Hadoop) environments, pushed to BDA storage level for execution.\n",
      "In bot cases, nly thos records that sality the predicates are plle fro disk fo er procesing sie the\n",
      "database. For example, find the US customers likely to churn:\n",
      "select cust id\n",
      "from customers\n",
      "where region = 'US'\n",
      "| Scoring function executed in Exadata or on BDA\n",
      "and prediction probability (churnmod\n",
      "using *) > 0.8;\n",
      "Automatic Data Preparation, Data Types, Star Schemas and \"Nested Tables'\n",
      "Typically, in order to perform proper analysis on data, analysts have to make explicit decisions about how to \"bin\"\n",
      "data, deal with missing values and oftentimes reduce the number of variables (feature selection) to be used in the\n",
      "models. Over the past 15 years, Oracle Advanced Analylics has evolved and now can automate most of the steps\n",
      "typically required in data mining projects. Today, Automated Data Preparation (ADP) automatically bins numeric\n",
      "attributes using defaul and us custoizable ing stragies e.g. equal wit equal count, us-defined and\n",
      "similarly bins calegorical attributes into Ntop values and other or user-defined bins. Missing values are\n",
      "from the analysis. ADP is used both for model building and then again for applying the models to new data. Users\n",
      "can of course override ADP settings if they choose.\n",
      "Oracle Advanced Analytics provides support for attribute reduction (Attribute Importance using the Minimum\n",
      "Description Length algorthm) and feature reduction techniques (Principal Components Analysis and Non-Negative\n",
      "Matrix Factorization). However, each of the Oracle Advanced Analytics algorithms (e.g. Decision Trees,\n",
      "Generalized Linear Regression, Support Vector Machines, Nalve Bayes, K-Means Clustering, Expectation\n",
      "Maximization Clustering, Anomaly Detection 1-Class SVMs, etc.) has their own buill-in automated strategies for\n",
      "attribute reduction and selection so the an explicit variable reduction step is optional but not necessary. Users of\n",
      "course can control algorithm and data preparation settings or accept the intelligent defaults.\n",
      "Transactional data, e.g. purchases, transactions, events, etc. represent much of the data that is important to build\n",
      "good predictive models. Oracle Advanced Analytics mines this data in its native transactional form and leverages\n",
      "the database's aggregation functions to summarize it and then feed vector of the data (e.g. item purchases) and join\n",
      "classification, regression and clustering models, ingest this aggregated transactional attribule as a \"nested table\".\n",
      "Dsep inside the Oracle Advanced Analytics in-database processing records are processed as tripet Unique_ID,\n",
      "Attribute_name, and Attribute_value. That's just part of the secret sauce of how Oracle Advanced Analytics\n",
      "leverages the core strengths of the Oracle Database. Market basket analysis would of course mine this data in its\n",
      "native transactional data form (typically not aggregated) to find co-occurring items in baskets.\n",
      "Unstructured data i.e. text is also processed in a similar fashion inside the database. Oracle Advanced Analytics\n",
      "uses Oracle Text's text processing capabilities and multi-language support to \"tokenize\" any CLOB data type e.g.\n",
      "7 | BIG DATA ANALYTICS WITH ORACLE ADVANCED ANALYTICS\n",
      "\n",
      "\n",
      "**************** PAGE NO. 12 ****************\n",
      "\n",
      "text, Word, Adobe Acrobat, etc. As Oracle Text is a free feature in every Oracle Database, Oracle Advanced\n",
      "Analytics leverages it to pre-process unstructured data to then feed vectors of words and word coefficients (TFIDF-\n",
      "term frequency inverse document frequency) into the algorithms. Oracle Advanced Analytics just treats the\n",
      "unstructured attributes as additional input attributes e.g. police comments, physician's notes, resume, emails, article,\n",
      "abstract, etc. that get joined with everything else (e.g. Age, Income, Occupation, etc.) that is being fed into the\n",
      "Oracle Advanced Analytics data mining algorithms. Spatial data, web clicks and other data types can also be\n",
      "joined and included in Oracle Advanced Analytics data mining models.\n",
      "Oracle Data Miner Workflow GUI; a SQL Developer extension\n",
      "Oracle Data Miner GUI, an extension to Oracle SQL Developer 4.1, is designed for users who prefer an easy to use\n",
      "GUI for their data analysis and don't necessarily want know have to know how to program in either SQL or R-or\n",
      "just don't want to write code. Oracle Data Miner enables data analysts, business analysts and data scientists to\n",
      "work directly with data nsi the database using Oracl Data Miner's graphical drg and drokwparadigm.\n",
      "Data anaysis easily ow o us Orac Data ine and can quickl visuaiz and plos the data graphically\n",
      "prepare and transform their data as necessary, build and evaluate multiple data mining models using extensive\n",
      "model viewing and model evaluation viewers. Then they can apply Oracle Data Mining models to new data for\n",
      "deployment and/or they can generate SQL and PL/SQL scripts to deploy Oracle Data Mining's predictive models\n",
      "throughout the enterprise.\n",
      "Oracle Data Miner work flows capture and document the user's analytical methodology and can be saved and\n",
      "shared with others to automate and publish advanced analytical methodologies.\n",
      "When the data analysts are done, Oracle Data Miner generates SQL scripts to pass to their DBAs for immediate\n",
      "deployment using the Cracle Database or combined data angment and predictive analyics. Application\n",
      "developers can programmatically call the orkows using the Oracl Data Miner PSQww AP to fully\n",
      "automate the discovery and distribution of new business intelligence and actionable insights and to integrate\n",
      "predictive methodologies into applications for wider use throughout the enterprise.\n",
      "B -\n",
      "| BIG DATA ANALYTICS WITH ORACLE ADVANCED ANALYTICS\n",
      "\n",
      "\n",
      "**************** PAGE NO. 13 ****************\n",
      "\n",
      "Orac Data Miner a SL Dev , rov a g ankuc for ata analyst to plore their\n",
      "data, bulld vas and apply c md ddey e caldoges as SL and PLSL scripss.\n",
      "Data analysts can use Oracle Data Miner to experiment and assemble very simple to complex advanced analytical\n",
      "methodologies. For example, a data analyst may want to combine transactional data, demographic data, customer\n",
      "service data and customer comments to assemble a 360 degree customer view. They may decide to perform\n",
      "clustering on e customers to pre ain the to ustomer ments and than for each smt build separate\n",
      "different classification, regression or anomaly detection models for better accuracy and usefulness.\n",
      "SQL Joins and arbitrery SQL\n",
      "POS data\n",
      "Transectione\n",
      "transforms & queries -power of SQL\n",
      "inline predictive\n",
      "medel to\n",
      "Build and apply\n",
      "multiple predictive\n",
      "eugment inpul\"\n",
      "models in-database\n",
      "for deployment\n",
      "Generates SQL scripts\n",
      "dota\n",
      "structured deta\n",
      "algerithms\n",
      "Database. All data, models and results remain inside the database.\n",
      "Oracle R Enterprise-Integrating Open Source R with the Oracle Database\n",
      "Oracle R Enterprise, a component of the Oracle Advanced Analytics Option, makes the open source R statistical\n",
      "programming language and environment ready for the enterprise and big data. \"R provides a wide variety of\n",
      "and graphical techniques, and is highly extensible\" (see https://www.rprojectorg). R's strengths are that it is free-\n",
      "open source, powerful and extensible, has an extensive array of graphical and statistical packages and is constantly\n",
      "being expanded by the R user community who author and contribute R \"packages\". R's challenges are that it is\n",
      "memory constrained, single threaded, runs an outer loop that can slow down processing and is not generally\n",
      "considered to be \"industrial strength\", Contributed R packages are of varying quality,\n",
      "Oracle R Enterprise integrates R with Oracle Database and maps R functions to equivalent SQL and Oracle Data\n",
      "Mining SQL functions and is designed for problems involving large amounts of data. It is a set of R packages (ORE)\n",
      "and Oracle Database features that enable an R user to operate on database-resident data without using SQL and to\n",
      "execute R scripts in one or more embedded R engines that run on the database server. Data analysts and data\n",
      "scientists can develop, refine, and deploy R scripts that leverage the parallelism and scalability of the database and\n",
      "the SQL data mining functions to automate data analysis in one step-without having to learn SQL\n",
      "Oracle R Enterprise has overloaded open source R methods and functions that transparently convert standard R\n",
      "syntax into SQL. These methods and functions are in ORE packages that implement the Oracle R Enterprise\n",
      "transparency layer. With these functions and methods, R programmers can create R objects that access, analyze\n",
      "8 | BIG DATA ANALYTICS WITH ORACLE ADVANCED ANALYTICS\n",
      "\n",
      "\n",
      "**************** PAGE NO. 14 ****************\n",
      "\n",
      "and manipulate data that resides in the database. The database automatically optimizes the SQL code to improve\n",
      "the fficienc of the quary Oracle ier ion wortbs excution of bas R\n",
      "Oracle SQL statistical functions, Oracle Data Mining SQL functions and selected popular R packages. Because it\n",
      "runs as an embedded component of Oracle Database, Oracle R Enterprise can run any R package either by\n",
      "function pushdown or via \"embedded R mode\" while the database manages the data served to the R engines. This\n",
      "\"embedded R mode\" ability allows developers to extend Oracle Advanced Analytics' natively supported toolkit with\n",
      "any open source R packages and develop wide ranging and automated advanced analytics methodologies that are\n",
      "completely managed by the database.\n",
      "3\n",
      "R Engine\n",
      "Other R\n",
      "SOL\n",
      "REngine\n",
      "other R\n",
      "packages\n",
      "package\n",
      "besults\n",
      "User R Engineon desktop\n",
      "Database Compute Engine\n",
      "REngine(s) spawined by Oracle DB\n",
      "8SCL Tramparency Framework overlouds Rt\n",
      "a Scale to large datasets\n",
      "functiors for scalable in-dlatabase execution\n",
      "Accesstables, views, and external tables, as\n",
      "well as data through DBLINES\n",
      "- Eficient data brarafer to spewned Rengines\n",
      "databuse-managedparalielom\n",
      "statbticalfunctions and advanced analytics\n",
      "Leverage database scs parallelsm\n",
      "pue sunsas peade o Aeylap ongesog\n",
      "Emulate map-reduce style algorithms and\n",
      "fow control as in standard R\n",
      "applic rons\n",
      "Submit user-defined iR functions for\n",
      "automated excecution of R scripts\n",
      "of Oracle Database\n",
      "Crade Advaced Aics Crade R Eeri (ORE copt y ushes down Ructions to quivet in-\n",
      "database SQL functions for scalability and paralleism. ORE users can also leverage any R packages via \"embedded R mode\"\n",
      "Users, who prefer to work in R to access and analyze their data, may use RStudio, or any R GUI, to connect to an\n",
      "Oracle Database and access Oracle Advanced Analytic's R integration (Oracle R Enterprise). Once a connection is\n",
      "made, the OAA/ORE session synchs the user's metadata so they see alltheir tables and views inside the database.\n",
      "When they run any base R language function it gets transparently mapped to equivalent SQL functions. R users\n",
      "using the OAA/ODM algorithms and OAA/ORE algorithms can perform scalable data mining in the database.\n",
      "10 | BIG DATA ANALYTICS WITH ORACLE ADVANCED ANALYTICS\n",
      "\n",
      "\n",
      "**************** PAGE NO. 15 ****************\n",
      "\n",
      "illla,\n",
      "IIll\n",
      ".II\n",
      "mIlam\n",
      "Oracle Advanced Analytics' Cracle R Enterprise component invoking in-database ODM algorithms (e.g., Support Vector Machine)\n",
      "from an RStudio cons\n",
      "Hadoop, Oracle Big Data Appliance and Big Data SQL\n",
      "Big data is n ot stored in Hadoop servers. The separate data viment ouside the databass introduces\n",
      "new data management and data analysis challenges. Big Data SQL addresses this challenge by extending SQL\n",
      "processing to Hadoop via the Oracle Big Data Appliance. Using \"smart scan\" technology developed for Exadata,\n",
      "Big Data SQL pushes down SQL logic to operate on Hive tables. Data analysts can now more easily take\n",
      "advantage of new big data sources of data of possibly unknown value stored in big data reservoirs and combine that\n",
      "data with data of known value managed inside a databese and/or data warehouse.\n",
      "However, the data stored in Hadoop may be voluminous and sparse representation (transactional format) and\n",
      "lacking in information density. Given that much of the data may come from sensors, Internet of Things, \"tweets\" and\n",
      "other high volume sources, users can leverage Big Data SQL to collect counts, maximum values, minimum values,\n",
      "thresholds counts above or below user defined values, averages, shorter term averages and counts and longer time\n",
      "averages and counts, sliding SQL window averages and counts and comperisons of each to the other. So, filter \"big\n",
      "data\", reduce it, join it to other database data using Oracle Big Data SQL and then mine *everything\" inside the\n",
      "Oracle Database using Oracle Advanced Analytics Option.\n",
      "11 | BIG DATA ANALYTICS WITH ORACLE ADVANCED ANALYTICS\n",
      "\n",
      "\n",
      "**************** PAGE NO. 16 ****************\n",
      "\n",
      "SQL\n",
      "SQL\n",
      "Store JSON data unconverted in Hadoop\n",
      "Store business-critical data in Oracle Data analyzed via SQL or R\n",
      "SQL and Big Data SQL enable data analysts to access, summarize, filter and aggregate data from both Hadoop servers and the\n",
      "Database and combine them for a more complete 360 degree customer view and build predictive models using Oracle Advanced\n",
      "Analytics.\n",
      "A Platform for Developing Enterprise-wide Predictive Analytics Applications\n",
      "Orace's stragy of making big data and big data anlics siple ake ea to develop refie and deploy\n",
      "predictive analytics applications-all is part of the database's functions. All the data, user access, security and\n",
      "encryption, scalability, applications development evironment and powerull advanced analytics are available in the\n",
      "data management and data analytics plafform-the Oracle Database. Now, it is easy to add predictive insights and\n",
      "real-time actionable insights into any enterprise application, Bl dashboard or tool that can speak SQL to the Oracle\n",
      "Database.\n",
      "Uters\n",
      "Data & Business Analysts R programmers\n",
      "Business Analysts/Mgrs\n",
      "Domain End Users\n",
      "SQL Developer\n",
      "RClient\n",
      "OBIEE\n",
      "Applications\n",
      "1 -\n",
      "Pletform\n",
      "Oracle Database Enterprise Edition\n",
      "Native SQL Data Mining/Analytic Functions + High-performar\n",
      "Oracle Advanced Analytics\n",
      "Rintegration for scalable, Distributed, Perallel Execution\n",
      "Orac Advanced Anayics, a separt ieeu of the racle Datbase nd the datas to a wnlyical\n",
      "aor both bi and b dat sich is ie o eving and delyin reve ics icaions\n",
      "Oracle has been developing predictive analytics applications and provides next-generation predictive applications on\n",
      "premise and in the cloud including:\n",
      "Oracle Human Capital Management Predictive Workforce\n",
      "Oracle Customer Relationship Management Sales Prediction Engine\n",
      "Oracle Adaptive Access Management's Identity Management\n",
      "Oracle Retail Customer Analytics\n",
      "12 | BIG DATAANALYTICS WITHORACLE ADVANCED ANALYTICS\n",
      "\n",
      "\n",
      "**************** PAGE NO. 17 ****************\n",
      "\n",
      "Dracle Predictive Incident Monitoring Premit\n",
      "Oracle Airines Industry Data Model\n",
      "\n",
      "\n",
      "**************** PAGE NO. 18 ****************\n",
      "\n",
      "..0\n",
      "Oracle Communications Data Model embeds OAA pre-buit predictive models for churn prediction, cus\n",
      "churn factors, cross-sell, customer life time value (LTV) and cuslomer sertiment.\n",
      "Conclusion\n",
      "Traditional Bl and analytic approaches simply can't keep pace with requirements era of \"big data\" and \"cloud\". For\n",
      "organizations who srive to be leaders in their areas leveraging these new technologies, the prompt capture and\n",
      "collection of data of known and unknown value, the proper data management, assembly of relevant data and facile\n",
      "deep analysis and automation and deployment of the actionable insights is the key to success.\n",
      "Oracle Advanced Analytics, a priced option to the Oracle Database 12c, collapses the traditional extract, move\n",
      "load, analyze, export, move, load/import paradigm all too common today. Oracle Advanced Analytics delivers\n",
      "scalable, paralelized, in-database implementations of a wide library of workhorse predictive analytics algorithms\n",
      "SQL functions within the Oracle Database 12c. Oracle Advanced Analytics exposes these predictive algorithms as\n",
      "SQL functions accessible via SOL (Oracle Dala Mining OAA SOL API component), the Orace Data Miner drag and\n",
      "drop\" workflow GUI, an extension to Oracle SQL Developer 4.1 and through tight integration w open source R\n",
      "(Oracle R Enterprise R integration component).\n",
      "Because Oracle Advanced Analytics' in-database data mining machine learning/predictive analytics algorithms are\n",
      "buil from the inside out of the racle Dabs and take ful advantage of the race Database's scalabilty\n",
      "security, integration, cloud, structured and unstructured data mining capabilities, it make Oracle the ideal platform for\n",
      "big data + analytics solutions and applications either on-premise or on the Oracle Cloud\n",
      "14 | BIG DATA ANALYTICS WITH ORACLE ADVANCED ANALYTICS\n",
      "\n",
      "\n",
      "**************** PAGE NO. 19 ****************\n",
      "\n",
      "With Cracle, data management and descriptive, predictive and prescriptive big data analytics are designed into the\n",
      "platform from the beginning. All of Oracle's multiple decades of leading edge data management and SQL and Big\n",
      "Data SQL is hamesses and combined with Oracle's design and development approach of \"moving the agonithms to\n",
      "the data\"vs. \"moving the data to the algorithms\". Oracle's vision is to create a big data and analytic platiorm for the\n",
      "era of big data and the cloud to:\n",
      "Make big data + analytics simple:\n",
      "Any variety of data, in any combination\n",
      "Make big data and analytics deployment simple\n",
      "As a service, as a platform, as an application\n",
      "By integrating both big data management and big data analytics into a single unified Oracle Database platform,\n",
      "Oracle reduces total cost of ownership, eliminates data movement, and delivers the fastest way to deliver\n",
      "enterprise-wide predictive analytics solutions and applications.\n",
      "15 | BIG DATA ANALYTICS WITH ORACLE ADVANCED ANALYTICS\n",
      "\n",
      "\n",
      "**************** PAGE NO. 20 ****************\n",
      "\n",
      "Oracle Corporation, World Headquarters\n",
      "Worldwide Inquiries\n",
      "ORACLE\n",
      "Recwood Shores, CA 94085, USA\n",
      "Phone: + 1.650.506.7000\n",
      "Fax: +1.650.506.7200\n",
      "CONNECT WITH US\n",
      "Hardware and Seftware, Engineered to Work Tegether\n",
      "apeie weo apeo stop\n",
      "Capsriott 2015. Oracle andir as atiates. A riates reserect. Thes document is prosided for indcoression purpases orly, and the\n",
      "cebook com/oracle\n",
      "warantes or conditions, whether epressed craly or implied in la, including implied worranties and conditors of merchotaby or\n",
      "finess for a paricular purpose. We specitically disclaim ary loabity with respect to this document, and no cortractual oblgations are\n",
      "witter.com/oracle\n",
      "formed either directy or indirectly by this document. This document may not be reproduced or trarsmitled in any form or by any\n",
      "acle.com\n",
      "Cracle and Java are registored trademarks of Cracle andor its afilates. Other names may be trademarks of their respective own\n",
      "Whee Prper Pife\n",
      "Jamuery 2015\n",
      "(TeNOULdol suoury furngsuery\n",
      "& |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "object_storage_client = oci.object_storage.ObjectStorageClient(config)\n",
    "\n",
    "index = randint(0, len(input_location.object_locations) - 1)\n",
    "object_location = input_location.object_locations[index]\n",
    "\n",
    "output_object_name = output_location.prefix + \"/\" + res.data.id + \"/\" + \\\n",
    "        object_location.namespace_name  + \"_\" + object_location.bucket_name + \"_\" + \\\n",
    "            object_location.object_name\n",
    "\n",
    "res_json = object_storage_client.get_object(output_location.namespace_name, \\\n",
    "    output_location.bucket_name, object_name = output_object_name+\".json\").data.content\n",
    "res_dict = json.loads(res_json)\n",
    "\n",
    "print(\"Document :\", object_location.object_name, '\\n')\n",
    "\n",
    "if 'pages' in res_dict:\n",
    "    for j, page in enumerate(res_dict['pages']):\n",
    "        print('**************** PAGE NO.', j+1, '****************\\n')\n",
    "\n",
    "        if len(page['lines']) == 0:\n",
    "            print(\"No text detected.\\n\")\n",
    "            continue\n",
    "\n",
    "        for line in page['lines']:\n",
    "            print(line['text'])\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39186b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
